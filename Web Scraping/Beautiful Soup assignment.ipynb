{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44f213a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of all header tags :\n",
      "\n",
      "[<h1 class=\"firstHeading\" id=\"firstHeading\">Main Page</h1>, <h2 class=\"mp-h2\" id=\"mp-tfa-h2\"><span id=\"From_today.27s_featured_article\"></span><span class=\"mw-headline\" id=\"From_today's_featured_article\">From today's featured article</span></h2>, <h2 class=\"mp-h2\" id=\"mp-dyk-h2\"><span class=\"mw-headline\" id=\"Did_you_know_...\">Did you know ...</span></h2>, <h2 class=\"mp-h2\" id=\"mp-itn-h2\"><span class=\"mw-headline\" id=\"In_the_news\">In the news</span></h2>, <h2 class=\"mp-h2\" id=\"mp-otd-h2\"><span class=\"mw-headline\" id=\"On_this_day\">On this day</span></h2>, <h2 class=\"mp-h2\" id=\"mp-tfp-h2\"><span id=\"Today.27s_featured_picture\"></span><span class=\"mw-headline\" id=\"Today's_featured_picture\">Today's featured picture</span></h2>, <h2 class=\"mp-h2\" id=\"mp-other\"><span class=\"mw-headline\" id=\"Other_areas_of_Wikipedia\">Other areas of Wikipedia</span></h2>, <h2 class=\"mp-h2\" id=\"mp-sister\"><span id=\"Wikipedia.27s_sister_projects\"></span><span class=\"mw-headline\" id=\"Wikipedia's_sister_projects\">Wikipedia's sister projects</span></h2>, <h2 class=\"mp-h2\" id=\"mp-lang\"><span class=\"mw-headline\" id=\"Wikipedia_languages\">Wikipedia languages</span></h2>, <h2>Navigation menu</h2>, <h3 aria-label=\"\" class=\"vector-menu-heading\" id=\"p-personal-label\">\n",
      "<span>Personal tools</span>\n",
      "</h3>, <h3 aria-label=\"\" class=\"vector-menu-heading\" id=\"p-namespaces-label\">\n",
      "<span>Namespaces</span>\n",
      "</h3>, <h3 aria-label=\"Change language variant\" class=\"vector-menu-heading\" id=\"p-variants-label\">\n",
      "<span>Variants</span>\n",
      "<span class=\"vector-menu-checkbox-expanded\">expanded</span>\n",
      "<span class=\"vector-menu-checkbox-collapsed\">collapsed</span>\n",
      "</h3>, <h3 aria-label=\"\" class=\"vector-menu-heading\" id=\"p-views-label\">\n",
      "<span>Views</span>\n",
      "</h3>, <h3 aria-label=\"\" class=\"vector-menu-heading\" id=\"p-cactions-label\">\n",
      "<span>More</span>\n",
      "<span class=\"vector-menu-checkbox-expanded\">expanded</span>\n",
      "<span class=\"vector-menu-checkbox-collapsed\">collapsed</span>\n",
      "</h3>, <h3>\n",
      "<label for=\"searchInput\">Search</label>\n",
      "</h3>, <h3 aria-label=\"\" class=\"vector-menu-heading\" id=\"p-navigation-label\">\n",
      "<span>Navigation</span>\n",
      "</h3>, <h3 aria-label=\"\" class=\"vector-menu-heading\" id=\"p-interaction-label\">\n",
      "<span>Contribute</span>\n",
      "</h3>, <h3 aria-label=\"\" class=\"vector-menu-heading\" id=\"p-tb-label\">\n",
      "<span>Tools</span>\n",
      "</h3>, <h3 aria-label=\"\" class=\"vector-menu-heading\" id=\"p-coll-print_export-label\">\n",
      "<span>Print/export</span>\n",
      "</h3>, <h3 aria-label=\"\" class=\"vector-menu-heading\" id=\"p-wikibase-otherprojects-label\">\n",
      "<span>In other projects</span>\n",
      "</h3>, <h3 aria-label=\"\" class=\"vector-menu-heading\" id=\"p-lang-label\">\n",
      "<span>Languages</span>\n",
      "</h3>]\n"
     ]
    }
   ],
   "source": [
    "#Q1)\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "page=requests.get(\"https://en.wikipedia.org/wiki/Main_Page\")\n",
    "page\n",
    "\n",
    "url=\"https://en.wikipedia.org/wiki/Main_Page\"\n",
    "\n",
    "html=urlopen(url)\n",
    "bs=BeautifulSoup(html,\"html.parser\")\n",
    "\n",
    "titles=bs.find_all(['h1','h2','h3','h4','h5','h6'])\n",
    "print(\"List of all header tags :\",titles,sep='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9af5536",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b0bc820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.220522404535997 - The Shawshank Redemption (1994) -\n",
      "9.147257698023923 - The Godfather (1972) -\n",
      "8.980529949402799 - The Godfather: Part II (1974) -\n",
      "8.973095364970735 - The Dark Knight (2008) -\n",
      "8.939228040008526 - 12 Angry Men (1957) -\n",
      "8.91112490113426 - Schindler's List (1993) -\n",
      "8.88838983297331 - The Lord of the Rings: The Return of the King (2003) -\n",
      "8.836008377472718 - Pulp Fiction (1994) -\n",
      "8.786310513919904 - Il buono, il brutto, il cattivo (1966) -\n",
      "8.778577184736646 -  The Lord of the Rings: The Fellowship of the Ring (2001) -\n",
      "8.752274750918051 - Fight Club (1999) -\n",
      "8.743870091112834 - Forrest Gump (1994) -\n",
      "8.714631105305092 - Inception (2010) -\n",
      "8.702098125173654 - The Lord of the Rings: The Two Towers (2002) -\n",
      "8.694797231343085 - Star Wars: Episode V - The Empire Strikes Back (1980) -\n",
      "8.645298380569148 - The Matrix (1999) -\n",
      "8.643768273063902 - Goodfellas (1990) -\n",
      "8.635140432355279 - One Flew Over the Cuckoo's Nest (1975) -\n",
      "8.609138960619516 - Shichinin no samurai (1954) -\n",
      "8.58724594087685 - Se7en (1995) -\n",
      "8.577046090031894 - The Silence of the Lambs (1991) -\n",
      "8.5762833975635 - Cidade de Deus (2002) -\n",
      "8.574690356305386 - La vita è bella (1997) -\n",
      "8.574148680583594 - It's a Wonderful Life (1946) -\n",
      "8.551623229003464 - Star Wars (1977) -\n",
      "8.549921631419505 - Saving Private Ryan (1998) -\n",
      "8.53918797775273 - Interstellar (2014) -\n",
      "8.538414645869105 - Sen to Chihiro no kamikakushi (2001) -\n",
      "8.535813897502626 - The Green Mile (1999) -\n",
      "8.527708082089083 - Gisaengchung (2019) -\n",
      "8.499552029599958 - Léon (1994) -\n",
      "8.495270599461561 - Seppuku (1962) -\n",
      "8.489433500527728 - The Pianist (2002) -\n",
      "8.48630357555511 - The Usual Suspects (1995) -\n",
      "8.484627616307714 - Terminator 2: Judgment Day (1991) -\n",
      "8.484290731045773 - Back to the Future (1985) -\n",
      "8.482101795513453 - Psycho (1960) -\n",
      "8.48092827813264 - The Lion King (1994) -\n",
      "8.480355654349436 - Modern Times (1936) -\n",
      "8.473768700192856 - American History X (1998) -\n",
      "8.471466248028381 - City Lights (1931) -\n",
      "8.470112224414597 - Hotaru no haka (1988) -\n",
      "8.468554026350745 - Whiplash (2014) -\n",
      "8.468239503860138 - Gladiator (2000) -\n",
      "8.466701237759407 - The Departed (2006) -\n",
      "8.459612830817557 - The Intouchables (2011) -\n",
      "8.452901914811768 - The Prestige (2006) -\n",
      "8.449527783440722 - Casablanca (1942) -\n",
      "8.447910232870232 - Once Upon a Time in the West (1968) -\n",
      "8.438931698977846 - Rear Window (1954) -\n",
      "8.43618795469996 - Nuovo Cinema Paradiso (1988) -\n",
      "8.422583937540068 - Alien (1979) -\n",
      "8.417578357412435 - Apocalypse Now (1979) -\n",
      "8.409332501632987 - Memento (2000) -\n",
      "8.406431696875249 - Raiders of the Lost Ark (1981) -\n",
      "8.404826897211024 - The Great Dictator (1940) -\n",
      "8.39127722256661 - The Lives of Others (2006) -\n",
      "8.389689922009753 - Django Unchained (2012) -\n",
      "8.382876834129233 - Paths of Glory (1957) -\n",
      "8.377167762282397 - Sunset Blvd (1950) -\n",
      "8.372944872191333 - WALL·E (2008) -\n",
      "8.365130866947972 - Avengers: Infinity War (2018) -\n",
      "8.36454742044859 - The Shining (1980) -\n",
      "8.363693678864031 - Witness for the Prosecution (1957) -\n",
      "8.354363324353077 - Spider-Man: Into the Spider-Verse (2018) -\n",
      "8.353139997650553 - Dr Strangelove or: How I Learned to Stop Worrying and Love the Bomb (1964) -\n",
      "8.348555370621462 - Joker (2019) -\n",
      "8.344784724361986 - Mononoke-hime (1997) -\n",
      "8.344269868937623 - Oldeuboi (2003) -\n",
      "8.326462703434974 - Kimi no na wa (2016) -\n",
      "8.322569099884564 - The Dark Knight Rises (2012) -\n",
      "8.322539959129196 - Once Upon a Time in America (1984) -\n",
      "8.321439149517696 - Coco (2017) -\n",
      "8.321436076094374 - Aliens (1986) -\n",
      "8.30999889170216 - Capharnaüm (2018) -\n",
      "8.308338878043225 - Avengers: Endgame (2019) -\n",
      "8.307014287369773 - Das Boot (1981) -\n",
      "8.30531790395646 - Hamilton (2020) -\n",
      "8.303893373208338 - Tengoku to jigoku (1963) -\n",
      "8.297982912135039 - American Beauty (1999) -\n",
      "8.296204237089183 - Toy Story (1995) -\n",
      "8.29594464625967 - 3 Idiots (2009) -\n",
      "8.294760324909028 - Amadeus (1984) -\n",
      "8.294138062506107 - Braveheart (1995) -\n",
      "8.287776149580756 - Inglourious Basterds (2009) -\n",
      "8.280877055095075 - Good Will Hunting (1997) -\n",
      "8.27482637254546 - Star Wars: Episode VI - Return of the Jedi (1983) -\n",
      "8.273195890046567 - 2001: A Space Odyssey (1968) -\n",
      "8.272019471512657 - Reservoir Dogs (1992) -\n",
      "8.270788076394652 - M - Eine Stadt sucht einen Mörder (1931) -\n",
      "8.270681725226313 - Taare Zameen Par (2007) -\n",
      "8.269147302803036 - Vertigo (1958) -\n",
      "8.267604265596205 - Citizen Kane (1941) -\n",
      "8.26699815707115 - Idi i smotri (1985) -\n",
      "8.26477192128134 - Jagten (2012) -\n",
      "8.261334433250509 - Requiem for a Dream (2000) -\n",
      "8.258883706805506 - Singin' in the Rain (1952) -\n",
      "8.25793424847666 - North by Northwest (1959) -\n",
      "8.256073161920673 - Eternal Sunshine of the Spotless Mind (2004) -\n",
      "8.25483879691182 -  Ladri di biciclette (1948) -\n",
      "8.25472140173518 - Ikiru (1952) -\n",
      "8.253104423047047 - Dune (2021) -\n",
      "8.252718804287198 - Pather Panchali (1955) -\n",
      "8.24975594964182 - Lawrence of Arabia (1962) -\n",
      "8.246035467645303 - The Kid (1921) -\n",
      "8.243234987338695 - Full Metal Jacket (1987) -\n",
      "8.24240968931242 - Dangal (2016) -\n",
      "8.2412448707527 - The Father (2020) -\n",
      "8.23764735860669 - The Apartment (1960) -\n",
      "8.237535658148898 - A Clockwork Orange (1971) -\n",
      "8.236494998341406 - Metropolis (1927) -\n",
      "8.236123726523772 - Taxi Driver (1976) -\n",
      "8.235975575142717 - Incendies (2010) -\n",
      "8.235094316021168 - Double Indemnity (1944) -\n",
      "8.233554506687119 - The Sting (1973) -\n",
      "8.23267194602816 - Jodaeiye Nader az Simin (2011) -\n",
      "8.232264565959868 - Scarface (1983) -\n",
      "8.231472807586226 - 1917 (2019) -\n",
      "8.23057874560175 - Snatch (2000) -\n",
      "8.230086725366688 - Le fabuleux destin d'Amélie Poulain (2001) -\n",
      "8.225603533614478 - Toy Story 3 (2010) -\n",
      "8.225520447732487 - To Kill a Mockingbird (1962) -\n",
      "8.21798202346003 - Per qualche dollaro in più (1965) -\n",
      "8.21345118076404 - Up (2009) -\n",
      "8.203794062751472 - Indiana Jones and the Last Crusade (1989) -\n",
      "8.200489396862856 - LA Confidential (1997) -\n",
      "8.19999388352586 - Heat (1995) -\n",
      "8.195141443205515 - Yôjinbô (1961) -\n",
      "8.194418133375768 - Rashômon (1950) -\n",
      "8.19389970517467 - Ran (1985) -\n",
      "8.193047655037212 - Die Hard (1988) -\n",
      "8.190317632943799 - Green Book (2018) -\n",
      "8.18897277818853 - Der Untergang (2004) -\n",
      "8.188407452025775 - Monty Python and the Holy Grail (1975) -\n",
      "8.186182946163706 - All About Eve (1950) -\n",
      "8.18413688931415 - Some Like It Hot (1959) -\n",
      "8.183714874835555 - Batman Begins (2005) -\n",
      "8.179247285542042 - Unforgiven (1992) -\n",
      "8.178401279740285 - Bacheha-Ye aseman (1997) -\n",
      "8.163723246586029 - Hauru no ugoku shiro (2004) -\n",
      "8.160955301733726 - The Wolf of Wall Street (2013) -\n",
      "8.157771180664584 - Judgment at Nuremberg (1961) -\n",
      "8.15694727002325 - The Great Escape (1963) -\n",
      "8.15399707912149 - Casino (1995) -\n",
      "8.153335464372077 - There Will Be Blood (2007) -\n",
      "8.1531779412552 - The Treasure of the Sierra Madre (1948) -\n",
      "8.149746561574583 - Pan's Labyrinth (2006) -\n",
      "8.148259044879044 - A Beautiful Mind (2001) -\n",
      "8.145644537094183 - El secreto de sus ojos (2009) -\n",
      "8.144465769788983 - Raging Bull (1980) -\n",
      "8.138426690571322 - Tonari no Totoro (1988) -\n",
      "8.137955922807693 - Chinatown (1974) -\n",
      "8.134429591434547 - Lock, Stock and Two Smoking Barrels (1998) -\n",
      "8.131080766684349 - The Gold Rush (1925) -\n",
      "8.130541164007454 - Shutter Island (2010) -\n",
      "8.128677414155547 - No Country for Old Men (2007) -\n",
      "8.128195676297617 - Dial M for Murder (1954) -\n",
      "8.127438730806315 - Det sjunde inseglet (1957) -\n",
      "8.126779406782324 - Three Billboards Outside Ebbing, Missouri (2017) -\n",
      "8.124295233165075 - The Elephant Man (1980) -\n",
      "8.123935039930789 - The Thing (1982) -\n",
      "8.12222444681313 - The Sixth Sense (1999) -\n",
      "8.119448328239574 - Klaus (2019) -\n",
      "8.116757717271387 - The Third Man (1949) -\n",
      "8.11622652478712 - Smultronstället (1957) -\n",
      "8.114238053947705 - V for Vendetta (2005) -\n",
      "8.11415481788507 - Jurassic Park (1993) -\n",
      "8.114152302171254 - The Truman Show (1998) -\n",
      "8.1135631239221 - Inside Out (2015) -\n",
      "8.113090474796783 - Salinui chueok (2003) -\n",
      "8.112237596772431 - Blade Runner (1982) -\n",
      "8.111991969770104 - Trainspotting (1996) -\n",
      "8.110974261778097 - The Bridge on the River Kwai (1957) -\n",
      "8.109659183496158 - Fargo (1996) -\n",
      "8.109558174432685 - Warrior (2011) -\n",
      "8.107974992867002 - Finding Nemo (2003) -\n",
      "8.10640646028411 - Kill Bill: Vol 1 (2003) -\n",
      "8.106296952379099 - Gone with the Wind (1939) -\n",
      "8.105638177673539 - Z (1969) -\n",
      "8.10549085674067 - Tôkyô monogatari (1953) -\n",
      "8.104045045104368 - Babam ve Oglum (2005) -\n",
      "8.101695356025989 - On the Waterfront (1954) -\n",
      "8.095026456281932 - Stalker (1979) -\n",
      "8.092637584066171 - Relatos salvajes (2014) -\n",
      "8.091540466616491 - Sherlock Jr (1924) -\n",
      "8.091105597566933 - The General (1926) -\n",
      "8.090794718338618 - The Deer Hunter (1978) -\n",
      "8.089455612316742 - Gran Torino (2008) -\n",
      "8.088247465878394 - Persona (1966) -\n",
      "8.086322282270423 - The Grand Budapest Hotel (2014) -\n",
      "8.085290289072002 - Prisoners (2013) -\n",
      "8.084469879614488 - Before Sunrise (1995) -\n",
      "8.084417551612637 - Mary and Max (2009) -\n",
      "8.08202029656689 - Mr Smith Goes to Washington (1939) -\n",
      "8.081078930496878 - Room (2015) -\n",
      "8.080658131180755 - In the Name of the Father (1993) -\n",
      "8.0803566406577 - Catch Me If You Can (2002) -\n",
      "8.078549740199472 - Barry Lyndon (1975) -\n",
      "8.077661223804991 - Gone Girl (2014) -\n",
      "8.076465035837142 - Hacksaw Ridge (2016) -\n",
      "8.075282294717159 - Andhadhun (2018) -\n",
      "8.073081437464415 - La passion de Jeanne d'Arc (1928) -\n",
      "8.07276757840585 - To Be or Not to Be (1942) -\n",
      "8.069488443077182 - Ford v Ferrari (2019) -\n",
      "8.068657000444718 - 12 Years a Slave (2013) -\n",
      "8.06754961553048 - The Big Lebowski (1998) -\n",
      "8.06296661471292 - How to Train Your Dragon (2010) -\n",
      "8.061316997630563 - Mad Max: Fury Road (2015) -\n",
      "8.060512255000209 - Dead Poets Society (1989) -\n",
      "8.060431579337118 - Höstsonaten (1978) -\n",
      "8.059665274431499 - Ben-Hur (1959) -\n",
      "8.058756069591118 - Million Dollar Baby (2004) -\n",
      "8.058169953375192 - Le salaire de la peur (1953) -\n",
      "8.057572475464536 - Harry Potter and the Deathly Hallows: Part 2 (2011) -\n",
      "8.055422481819546 - Stand by Me (1986) -\n",
      "8.055319119688999 - Ah-ga-ssi (2016) -\n",
      "8.055186931664764 - Network (1976) -\n",
      "8.051113085980932 - Logan (2017) -\n",
      "8.050900559973202 - Cool Hand Luke (1967) -\n",
      "8.050325305886444 - Les quatre cents coups (1959) -\n",
      "8.049590598320558 - Gangs of Wasseypur (2012) -\n",
      "8.04879577970235 - Hachi: A Dog's Tale (2009) -\n",
      "8.048237657384737 - La haine (1995) -\n",
      "8.04661050736737 - Platoon (1986) -\n",
      "8.045038357264001 - Eskiya (1996) -\n",
      "8.044002638783898 - Spotlight (2015) -\n",
      "8.043717322093263 - Koe no katachi (2016) -\n",
      "8.04154157872349 - Life of Brian (1979) -\n",
      "8.0412210352169 - Rebecca (1940) -\n",
      "8.040729920166898 - Monsters, Inc (2001) -\n",
      "8.039554459450896 - Hotel Rwanda (2004) -\n",
      "8.038786694576876 - Fa Yeung Nin Wah (2000) -\n",
      "8.037970482149323 - Rush (2013) -\n",
      "8.036729977996183 - Into the Wild (2007) -\n",
      "8.035073495097784 - Amores perros (2000) -\n",
      "8.034075879880952 - Rocky (1976) -\n",
      "8.033855119090562 - Andrei Rublev (1966) -\n",
      "8.031057221509466 - Kaze no tani no Naushika (1984) -\n",
      "8.030925798539249 - It Happened One Night (1934) -\n",
      "8.029331307328825 - Shin seiki Evangelion Gekijô-ban: Air/Magokoro wo, kimi ni (1997) -\n",
      "8.027642167429597 - Before Sunset (2004) -\n",
      "8.027363937182548 - La battaglia di Algeri (1966) -\n",
      "8.026779682899553 - Fanny och Alexander (1982) -\n",
      "8.024354312269207 - Trois couleurs: Rouge (1994) -\n",
      "8.023218869692114 - Paris, Texas (1984) -\n",
      "8.023087873214624 - Kimetsu no Yaiba: Mugen Ressha-Hen (2020) -\n",
      "8.022754590290441 - The Princess Bride (1987) -\n",
      "8.020690246640543 - Le notti di Cabiria (1957) -\n",
      "8.020373117639041 - Du rififi chez les hommes (1955) -\n",
      "8.01922899256108 - Ratsasan (2018) -\n"
     ]
    }
   ],
   "source": [
    "#Q2. Write a python program to display IMDB's Top rated 100 movies' data (i.e.Name,IMDB rating,Year of release)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from requests import get\n",
    "import lxml\n",
    "\n",
    "url = 'http://www.imdb.com/chart/top'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'lxml')\n",
    "\n",
    "movies = soup.select('td.titleColumn')\n",
    "\n",
    "links = [a.attrs.get('href') for a in soup.select('td.titleColumn a')]\n",
    "\n",
    "ratings = [b.attrs.get('data-value') for b in soup.select('td.posterColumn span[name=ir]')]\n",
    "votes = [b.attrs.get('data-value') for b in soup.select('td.ratingColumn strong')]\n",
    "imdb = []\n",
    "\n",
    "for index in range(0, len(movies)):\n",
    "    \n",
    "    movie_string = movies[index].get_text()\n",
    "    movie = (' '.join(movie_string.split()).replace('.', ''))\n",
    "    movie_title = movie[len(str(index))+1:-7]\n",
    "    year = re.search('\\((.*?)\\)', movie_string).group(1)\n",
    "    \n",
    "    data = {\"movie_title\": movie_title,\n",
    "            \"year \": year,\n",
    "            \"rating\": ratings[index]}\n",
    "           \n",
    "            \n",
    "    imdb.append(data)\n",
    "\n",
    "for item in imdb:\n",
    "    print(item['rating'], '-', item['movie_title'], '('+item['year ']+') -')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e2810d54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year of Release</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nayakan</td>\n",
       "      <td>(1987)</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Anbe Sivam</td>\n",
       "      <td>(2003)</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pariyerum Perumal</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C/o Kancharapalem</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Golmaal</td>\n",
       "      <td>(1979)</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Rang De Basanti</td>\n",
       "      <td>(2006)</td>\n",
       "      <td>8.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>OMG: Oh My God!</td>\n",
       "      <td>(2012)</td>\n",
       "      <td>8.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Roja</td>\n",
       "      <td>(1992)</td>\n",
       "      <td>8.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Uri: The Surgical Strike</td>\n",
       "      <td>(2019)</td>\n",
       "      <td>8.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Lagaan: Once Upon a Time in India</td>\n",
       "      <td>(2001)</td>\n",
       "      <td>8.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Name Year of Release Rating\n",
       "1                              Nayakan          (1987)    8.5\n",
       "2                           Anbe Sivam          (2003)    8.5\n",
       "3                    Pariyerum Perumal          (2018)    8.5\n",
       "4                    C/o Kancharapalem          (2018)    8.5\n",
       "5                              Golmaal          (1979)    8.5\n",
       "..                                 ...             ...    ...\n",
       "96                     Rang De Basanti          (2006)    8.1\n",
       "97                     OMG: Oh My God!          (2012)    8.1\n",
       "98                                Roja          (1992)    8.1\n",
       "99            Uri: The Surgical Strike          (2019)    8.1\n",
       "100  Lagaan: Once Upon a Time in India          (2001)    8.1\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q3)\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "req=requests.get('https://www.imdb.com/india/top-rated-indian-movies/')\n",
    "Soup=BeautifulSoup(req.content)\n",
    "movs=Soup.find_all('td',class_='titleColumn')\n",
    "movs100=movs[0:100]\n",
    "Mname=[]\n",
    "Year=[]\n",
    "for m in movs100:\n",
    "    name=m.a.text\n",
    "    year=m.span.text\n",
    "    Mname.append(name)\n",
    "    Year.append(year)\n",
    "rate=Soup.find_all('td',class_='ratingColumn imdbRating')\n",
    "rate100=rate[0:100]\n",
    "IMDB=[]\n",
    "for r in rate100:\n",
    "    imdb=r.strong.text\n",
    "    IMDB.append(imdb)\n",
    "INDTOP=pd.DataFrame({'Name':Mname,'Year of Release':Year,'Rating':IMDB},index=range(1,101))\n",
    "INDTOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "012769d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Review</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Author_Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sarah Ruhl</td>\n",
       "      <td>A playwright with an incredible eye for detail...</td>\n",
       "      <td>Nonfiction , Memoir</td>\n",
       "      <td>Kelly Blewett</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tips for Teachers: Embrace your silly side</td>\n",
       "      <td>Experienced teacher and children’s librarian E...</td>\n",
       "      <td>Children's , Picture Book</td>\n",
       "      <td>Emmie Stuart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Every</td>\n",
       "      <td>Unplug your Alexa and toss your Apple Watch. T...</td>\n",
       "      <td>Fiction , Satire</td>\n",
       "      <td>Amy Scribner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We Are Not Like Them</td>\n",
       "      <td>Hopelessness is certainly a theme in We Are No...</td>\n",
       "      <td>Fiction , Literary Fiction</td>\n",
       "      <td>Jessica Wakeman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The Lincoln Highway</td>\n",
       "      <td>The pages of Amor Towles’ novel are destined t...</td>\n",
       "      <td>Fiction , Historical Fiction</td>\n",
       "      <td>Alice Cary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Light From Uncommon Stars</td>\n",
       "      <td>In addition to its all-the-feels poignancy, Li...</td>\n",
       "      <td>Science Fiction &amp; Fantasy , Science Fiction</td>\n",
       "      <td>Thane Tierney</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Name  \\\n",
       "1                                  Sarah Ruhl   \n",
       "2  Tips for Teachers: Embrace your silly side   \n",
       "3                                   The Every   \n",
       "4                        We Are Not Like Them   \n",
       "5                         The Lincoln Highway   \n",
       "6                   Light From Uncommon Stars   \n",
       "\n",
       "                                              Review  \\\n",
       "1  A playwright with an incredible eye for detail...   \n",
       "2  Experienced teacher and children’s librarian E...   \n",
       "3  Unplug your Alexa and toss your Apple Watch. T...   \n",
       "4  Hopelessness is certainly a theme in We Are No...   \n",
       "5  The pages of Amor Towles’ novel are destined t...   \n",
       "6  In addition to its all-the-feels poignancy, Li...   \n",
       "\n",
       "                                         Genre       Author_Name  \n",
       "1                          Nonfiction , Memoir     Kelly Blewett  \n",
       "2                    Children's , Picture Book      Emmie Stuart  \n",
       "3                             Fiction , Satire      Amy Scribner  \n",
       "4                   Fiction , Literary Fiction   Jessica Wakeman  \n",
       "5                 Fiction , Historical Fiction        Alice Cary  \n",
       "6  Science Fiction & Fantasy , Science Fiction     Thane Tierney  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q4)\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "request=requests.get('https://bookpage.com/')\n",
    "soup=BeautifulSoup(request.content)\n",
    "dv=soup.find_all('div',class_='content')\n",
    "Book={'Name':[],'Review':[],'Genre':[],'Author_Name':[]}\n",
    "for i in dv:\n",
    "    nam=i.find('h4',class_='italic').text.replace('\\n','').replace(' ★ ','')\n",
    "    rev=i.find('p',class_='excerpt').text.replace('\\n','')\n",
    "    Gen=i.find('p',class_='genre-links hidden-phone').text.replace('/',',').replace('\\n','')\n",
    "    Auth=i.find('p',class_='sans bold').text.replace('\\n','').replace('Interview by','').replace('Feature by','').replace('Review by','')\n",
    "    Book['Name'].append(nam)\n",
    "    Book['Review'].append(rev)\n",
    "    Book['Genre'].append(Gen)\n",
    "    Book['Author_Name'].append(Auth)\n",
    "Books=pd.DataFrame(Book,index=range(1,7))\n",
    "Books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4ceb074a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player_Name</th>\n",
       "      <th>Team_Name</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Virat Kohli</td>\n",
       "      <td>IND</td>\n",
       "      <td>844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rohit Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ross Taylor</td>\n",
       "      <td>NZ</td>\n",
       "      <td>801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aaron Finch</td>\n",
       "      <td>AUS</td>\n",
       "      <td>779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jonny Bairstow</td>\n",
       "      <td>ENG</td>\n",
       "      <td>775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>David Warner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Shai Hope</td>\n",
       "      <td>WI</td>\n",
       "      <td>758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Kane Williamson</td>\n",
       "      <td>NZ</td>\n",
       "      <td>754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Quinton de Kock</td>\n",
       "      <td>SA</td>\n",
       "      <td>747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Fakhar Zaman</td>\n",
       "      <td>PAK</td>\n",
       "      <td>741</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Player_Name Team_Name Rating\n",
       "1       Virat Kohli       IND    844\n",
       "2      Rohit Sharma       IND    813\n",
       "3       Ross Taylor        NZ    801\n",
       "4       Aaron Finch       AUS    779\n",
       "5    Jonny Bairstow       ENG    775\n",
       "6      David Warner       AUS    762\n",
       "7         Shai Hope        WI    758\n",
       "8   Kane Williamson        NZ    754\n",
       "9   Quinton de Kock        SA    747\n",
       "10     Fakhar Zaman       PAK    741"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q5)\n",
    "#1)\n",
    "import requests\n",
    "from bs4 import BeautifulSoup \n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "req=requests.get('https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting')\n",
    "soup=BeautifulSoup(req.content)\n",
    "player=soup.find_all('tr',class_={'ranking-block__banner','table-body'})\n",
    "\n",
    "top10=player[0:10]\n",
    "data={'Player_Name':[],'Team_Name':[],'Rating':[]}\n",
    "\n",
    "for i in top10:\n",
    "    bat=i.find_all('td',recursive=True)\n",
    "    data['Player_Name'].append(bat[1].text.replace('\\n',''))\n",
    "    data['Team_Name'].append(bat[2].text.replace('\\n',''))\n",
    "    data['Rating'].append(bat[3].text.replace('\\n',''))\n",
    "    \n",
    "M_All=pd.DataFrame(data,index=range(1,11))\n",
    "M_All\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9580d149",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2)\n",
    "req=requests.get('https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling')\n",
    "soup=BeautifulSoup(req.content)\n",
    "player=soup.find_all('tr',class_={'ranking-block__banner','table-body'})\n",
    "\n",
    "top10=player[0:10]\n",
    "data={'Player_Name':[],'Team_Name':[],'Rating':[]}\n",
    "\n",
    "for i in top10:\n",
    "    bowl=i.find_all('td',recursive=True)\n",
    "    data['Player_Name'].append(bowl[1].text.replace('\\n',''))\n",
    "    data['Team_Name'].append(bowl[2].text.replace('\\n',''))\n",
    "    data['Rating'].append(bowl[3].text.replace('\\n',''))\n",
    "    \n",
    "M_Bowl=pd.DataFrame(data,index=range(1,11))\n",
    "M_Bowl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d024463",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3)\n",
    "req=requests.get('https://www.icc-cricket.com/rankings/mens/team-rankings/odi')\n",
    "soup=BeautifulSoup(req.content)\n",
    "player=soup.find_all('tr',class_={'ranking-block__banner','table-body'})\n",
    "\n",
    "top10=player[0:10]\n",
    "data={'Player_Name':[],'Team_Name':[],'Rating':[]}\n",
    "\n",
    "for i in top10:\n",
    "    team=i.find_all('td',recursive=True)\n",
    "    data['Player_Name'].append(team[1].text.replace('\\n',''))\n",
    "    data['Team_Name'].append(team[2].text.replace('\\n',''))\n",
    "    data['Rating'].append(team[3].text.replace('\\n',''))\n",
    "    \n",
    "Team_All=pd.DataFrame(data,index=range(1,11))\n",
    "Team_All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98183ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q6)i)\n",
    "req=requests.get('https://www.icc-cricket.com/rankings/womens/player-rankings/odi/all-rounder')\n",
    "soup=BeautifulSoup(req.content)\n",
    "player=soup.find_all('tr',class_={'ranking-block__banner','table-body'})\n",
    "\n",
    "top10=player[0:10]\n",
    "data={'Player_Name':[],'Team_Name':[],'Rating':[]}\n",
    "\n",
    "for i in top10:\n",
    "    bat=i.find_all('td',recursive=True)\n",
    "    data['Player_Name'].append(bat[1].text.replace('\\n',''))\n",
    "    data['Team_Name'].append(bat[2].text.replace('\\n',''))\n",
    "    data['Rating'].append(bat[3].text.replace('\\n',''))\n",
    "    \n",
    "W_All=pd.DataFrame(data,index=range(1,11))\n",
    "W_All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d872a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ii)\n",
    "req=requests.get('https://www.icc-cricket.com/rankings/womens/player-rankings/odi')\n",
    "soup=BeautifulSoup(req.content)\n",
    "player=soup.find_all('tr',class_={'ranking-block__banner','table-body'})\n",
    "\n",
    "top10=player[0:10]\n",
    "data={'Player_Name':[],'Team_Name':[],'Rating':[]}\n",
    "\n",
    "for i in top10:\n",
    "    bat=i.find_all('td',recursive=True)\n",
    "    data['Player_Name'].append(bat[1].text.replace('\\n',''))\n",
    "    data['Team_Name'].append(bat[2].text.replace('\\n',''))\n",
    "    data['Rating'].append(bat[3].text.replace('\\n',''))\n",
    "    \n",
    "W_All=pd.DataFrame(data,index=range(1,11))\n",
    "W_All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ea5ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#iii)\n",
    "req=requests.get('https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling')\n",
    "soup=BeautifulSoup(req.content)\n",
    "bowler=soup.find_all('tr',class_=('rankings-block__banner','table-body'))\n",
    "Top10=bowler[0:10]\n",
    "bdata={'Player_Name':[],'Team_Name': [], 'Rating':[]}\n",
    "for i in Top10:\n",
    "    bat=i.find_all('td',recursive=True)\n",
    "    bdata['Player_Name'].append(bat[1].text.replace('\\n',''))\n",
    "    bdata['Team_Name'].append(bat[2].text.replace('\\n',''))\n",
    "    bdata['Rating'].append(bat[3].text.replace('\\n',''))\n",
    "ODIBOWL=pd.DataFrame(bdata,index=range(1,11))\n",
    "ODIBOWL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1e56db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q7)\n",
    "page=requests.get(\"https://www.amazon.in/s?k=smartphones+under+20000+rupees+only&crid=3QV1RABX4EPDF&sprefix=smartphones+under+20000+rupees%2Caps%2C369&ref=nb_sb_ss_ts-doa-p_3_30\")\n",
    "print(page) # to check the response output\n",
    "soup=BeautifulSoup(page.content)\n",
    "\n",
    "# extract mobile names\n",
    "mob_name=soup.find_all(\"span\", class_=\"a-size-medium a-color-base a-text-normal\")\n",
    "product_names=[]\n",
    "for i in mob_name[:10]:\n",
    "    product_names.append(i.text)\n",
    "\n",
    "# extract mobile prices\n",
    "mob_price=soup.find_all(\"span\", class_=\"a-price-whole\")\n",
    "product_price=[]\n",
    "for i in mob_price[:10]:\n",
    "    product_price.append(i.text)\n",
    "\n",
    "# extract image urls\n",
    "images=soup.find_all(\"div\", class_=\"a-section aok-relative s-image-fixed-height\")\n",
    "images_url=[]\n",
    "for i in images[:10]:\n",
    "    for j in i.find_all(\"img\", class_=\"s-image\"):\n",
    "        images_url.append(j.get(\"src\"))\n",
    "\n",
    "# extract product ratings\n",
    "avg_rating=soup.find_all(\"i\", class_=\"a-icon a-icon-star-small a-star-small-4 aok-align-bottom\")\n",
    "ratings=[]\n",
    "for i in avg_rating[:10]:\n",
    "    ratings.append(i.text)\n",
    "\n",
    "# checking the length of the columns\n",
    "print(f\"Length of product name, price, image url and ratings\", len(product_names), \n",
    "      len(product_price), len(images_url), len(ratings))\n",
    "\n",
    "# creating the dataframe\n",
    "df=pd.DataFrame({})\n",
    "df[\"Product Names\"]=product_names\n",
    "df[\"Product Prices\"]=product_price\n",
    "df[\"Image Urls\"]=images_url\n",
    "df[\"Average Rating\"]=ratings\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e548bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q8\n",
    "page=requests.get(\"https://forecast.weather.gov/MapClick.php?lat=37.777120000000025&lon=-122.41963999999996#.YP_Um45LhPY\")\n",
    "print(page) # to get the response output\n",
    "soup=BeautifulSoup(page.content)\n",
    "\n",
    "# get the period names\n",
    "period=soup.find_all(\"p\", class_=\"period-name\")\n",
    "period_names=[]\n",
    "for i in period:\n",
    "    period_names.append(i.text)\n",
    "\n",
    "# get short description\n",
    "short_desc=soup.find_all(\"p\", class_=\"short-desc\")\n",
    "short_detail=[]\n",
    "for i in short_desc:\n",
    "    short_detail.append(i.text)\n",
    "\n",
    "# get the temperature details\n",
    "temp1=soup.find_all(\"p\", class_=\"temp temp-low\")\n",
    "temp2=soup.find_all(\"p\", class_=\"temp temp-high\")\n",
    "temperature=[]\n",
    "for i in temp1:\n",
    "    temperature.append(i.text)\n",
    "for i in temp2:\n",
    "    temperature.append(i.text)\n",
    "\n",
    "# get the full description\n",
    "long_desc=soup.find_all(\"div\", class_=\"col-sm-10 forecast-text\")\n",
    "description=[]\n",
    "for i in long_desc[:9]:\n",
    "    description.append(i.text)\n",
    "\n",
    "# checking the length of the columns\n",
    "print(f\"Length of period, short description, temperature and long description are:\", len(period_names), \n",
    "      len(short_detail), len(temperature), len(description))\n",
    "\n",
    "# creating the dataframe\n",
    "df=pd.DataFrame({})\n",
    "df['Period Names']=period_names\n",
    "df['Short Detail']=short_detail\n",
    "df['Temperature']=temperature\n",
    "df['Description']=description\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0841573b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q9)\n",
    "\n",
    "page=requests.get(\"https://internshala.com/fresher-jobs\")\n",
    "print(page) # to get the response output\n",
    "soup=BeautifulSoup(page.content)\n",
    "\n",
    "# get the job titles\n",
    "job_title=soup.find_all(\"div\", class_=\"heading_4_5 profile\")\n",
    "title=[]\n",
    "for i in job_title:\n",
    "    title.append(i.text.replace(\"\\n\",\"\").strip())\n",
    "\n",
    "# get the company names\n",
    "company_names=soup.find_all(\"div\", class_=\"heading_6 company_name\")\n",
    "company=[]\n",
    "for i in company_names:\n",
    "    company.append(i.text.replace(\"\\n\",\"\").strip())\n",
    "\n",
    "# get the CTC details\n",
    "CTC_list=soup.find_all(\"div\", class_=\"item_body\")\n",
    "CTC=[]\n",
    "for i in CTC_list:\n",
    "    for j in i.find_all(\"i\"):\n",
    "        CTC.append(i.text.replace(\"\\n\",\"\").strip())\n",
    "\n",
    "# get the apply dates for jobs\n",
    "applying=soup.find_all(\"div\", class_=\"item_body\")\n",
    "apply_date=[]\n",
    "for i in applying:\n",
    "    apply_date.append(i.text)\n",
    "dates=[]\n",
    "for i in range(2, len(apply_date), 3):\n",
    "    dates.append(apply_date[i])\n",
    "\n",
    "# checking the length of the columns\n",
    "print(f\"Lengths of Job title, Company name, CTC and Apply date are:\", len(title), len(company), len(CTC), len(dates))\n",
    "\n",
    "# creating the dataframe\n",
    "df=pd.DataFrame({})\n",
    "df['Job Title']=title\n",
    "df['Company Name']=company\n",
    "df['CTC']=CTC\n",
    "df['Apply Date']=dates\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "204d81ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q10)\n",
    "req=requests.get('https://www.nobroker.in/property/sale/bangalore/Whitefield?searchParam=W3sibGF0IjoxMi45Njk4MTk2LCJsb24iOjc3Ljc0OTk3MjEsInBsYWNlSWQiOiJDaElKZ193TlhmTVJyanNSLVJVQjJCS2x6ekEiLCJwbGFjZU5hbWUiOiJXaGl0ZWZpZWxkIn1d&radius=2.0&type=BHK2')\n",
    "soup=BeautifulSoup(req.content)\n",
    "\n",
    "nam=soup.find_all('h2',class_='heading-6 font-semi-bold nb__1AShY')\n",
    "name=[]\n",
    "for i in nam:\n",
    "    q=i.find('span').text\n",
    "    name.append(q)\n",
    "\n",
    "l_c=soup.find_all('div',class_='nb__35Ol7')\n",
    "addr=[]\n",
    "for l in l_c:\n",
    "    y=l.text.replace('Explore Nearby','')\n",
    "    addr.append(y)\n",
    "\n",
    "em=soup.find_all('div',class_='nb__17R6o')\n",
    "epi=[]\n",
    "ar=[]\n",
    "for y in em:\n",
    "    r=y.find('div',class_=\"font-semi-bold heading-6\",id=\"roomType\").text.replace('/Month','')\n",
    "    epi.append(r)\n",
    "    v=y.find('div',class_='font-semi-bold heading-6',recursive=True).text\n",
    "    ar.append(v)\n",
    "\n",
    "\n",
    "er=soup.find_all('div',class_='nb__2NPHR',id='minDeposit',itemprop='valueReference',itemtype=True)\n",
    "C=[]\n",
    "for n in er:\n",
    "    c=n.span.text\n",
    "    C.append(c)\n",
    "\n",
    "House=pd.DataFrame({},index=range(1,11))\n",
    "House['House_Title']=name\n",
    "House['Address']=addr\n",
    "House['EMI']=epi\n",
    "House['Area']=ar\n",
    "House['Price']=C\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bee3a1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab709b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eba1e25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
